[paths]
model_name = "1000_classic_small"
model_path = "models/1000_images/"
model_checkpoint_path = "models/model_checkpoint/"
load_model = None #"models/testruns/bolond_plusz_original_mix_10000_original_9784"

[data_loader]
batch_size_train = 100
batch_size_validate = 1024
batch_size_test = 0
dataset = 'mnist' # cifar100, cifar10, mnist
num_data_samples_train = 1000
num_data_samples_mcts = 0  
num_data_samples_val_test = 10000
val_test_split = 0.0
augmentation = 1
validate_with_test = 0
num_workers = 6

[callbacks]
neptune_logger = 1
neptune_token = "eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJkZGI5ZDY0Ni03MTEyLTQ2N2UtOTRlMC0zYzBlZmI1ODAxMTkifQ=="
neptune_project = "bvencl/mcts-new-methods"
start_with_zero = 0
model_checkpoint = 1
model_checkpoint_type = 'accuracy' # accuracy, loss
checkpoint_with_validation_data = 1
model_checkpoint_verbose = 1
remove_previous_checkpoint_at_start = 1

[trainer]
seed = 42
dropout_off = 0
n_epochs = 300
model_type = "mobilenet_v3_small" # mobilenet_v3_small, mobilenet_v3_large, resnet50
transfer_learning = 1

[agent]
lr_decay = 1
lr_decay_type = "exp" # cos, warmup_cos, lin, exp
warmup_epochs = 20
lr_start = 1e-2
lr_warmup_end = 3e-3
lr_end = 1e-2
exp_gamma = 0.97
lr_verbose = 1
loss = 'cross_entropy' # cross_entropy, focal_loss
optimizer = 'adam' # sgd, adam, rmsprop

[mcts]
n_iters_start = 1000
n_iters_max = 3000
c_param = 1.41
rollout = 1
checkpoint_loading = 0
branching_mode = 'factor' # max, factor
branching_factor = 5
default_exploit_multiplier = 10
increasing_exploit_multiplier = 0
max_exploit_multiplier = 150
min_exploit_multiplier = 10
exploit_multiplier_kick_in = 3
exploit_multiplier_steps = 10
