[paths]
model_name = "model"
model_path = "models/testruns/"
model_checkpoint_path = "models/model_checkpoint/"
load_model = None

[data_loader]
batch_size_train = 1024
batch_size_validate = 1024
batch_size_test = 0
dataset = 'mnist' # cifar100, cifar10, mnist
num_data_samples_train = 2049
num_data_samples_mcts = 5000
num_data_samples_val_test = 10000
val_test_split = 0.0
augmentation = 1
validate_with_test = 0
num_workers = 6

[callbacks]
neptune_logger = 1
neptune_token = "eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJkZGI5ZDY0Ni03MTEyLTQ2N2UtOTRlMC0zYzBlZmI1ODAxMTkifQ=="
neptune_project = "bvencl/mcts-batch-optimization"
model_checkpoint = 1
model_checkpoint_type = 'accuracy' # accuracy, loss
checkpoint_with_validation_data = 1
model_checkpoint_verbose = 1
remove_previous_checkpoint_at_start = 1

[trainer]
seed = 0

n_epochs = 20
model_type = "mobilenet_v3_small" # mobilenet_v3_small, mobilenet_v3_large, resnet50
transfer_learning = 1

[agent]
lr_decay = 1
lr_decay_type = "warmup_cos" # cos, warmup_cos, lin, exp
starting_learning_rate = 0.001
lr_min = 0.00001
warmup_epochs = 10
warmup_lr_high = 0.01
loss = 'cross_entropy' # cross_entropy, focal_loss
optimizer = 'adam' # sgd, adam, rmsprop

[mcts]
n_iters = 4000
c_param = 1.41
rollout = 1
branching_mode = 'max' # max, factor
branching_factor = 2